import os
import time
import requests
import base64
import subprocess
from datetime import datetime

# === âœ… è¨­å®šé … ===
CONDA_ENV = "ultralytics"  # ä½ çš„ Conda ç’°å¢ƒåç¨±
WEBUI_DIR = r"C:\Users\User\Desktop\OllamaAgent\stable-diffusion-webui"  # WebUI è³‡æ–™å¤¾
API_URL = "http://127.0.0.1:7860"
TXT2IMG_URL = f"{API_URL}/sdapi/v1/txt2img"
OPTIONS_URL = f"{API_URL}/sdapi/v1/options"
MODELS_URL = f"{API_URL}/sdapi/v1/sd-models"
OUTPUT_DIR = "stable_diffusion_output"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# === âœ… WebUI å•Ÿå‹•æª¢æŸ¥ ===
def is_webui_running() -> bool:
    try:
        res = requests.get(MODELS_URL, timeout=3)
        return res.status_code == 200
    except:
        return False

def launch_webui():
    print("ğŸš€ Stable Diffusion WebUI not running, launching it...")
    command = f'conda run -n {CONDA_ENV} python launch.py --api'
    subprocess.Popen(command, cwd=WEBUI_DIR, shell=True)
    print("ğŸ• Waiting for WebUI to start...")

    for i in range(60):
        if is_webui_running():
            print("âœ… WebUI is now running.")
            return True
        time.sleep(2)
    print("âŒ Timeout: WebUI did not start within 60 seconds.")
    return False

# === âœ… æ¨¡å‹ç›¸é—œæ“ä½œ ===
def list_available_models():
    try:
        res = requests.get(MODELS_URL)
        res.raise_for_status()
        models = res.json()
        print("ğŸ“¦ Available Models:")
        for m in models:
            print(f" - {m['title']} ({m['model_name']})")
        return [m['title'] for m in models]
    except Exception as e:
        print(f"âŒ Error listing models: {e}")
        return []

def switch_model(model_name: str):
    try:
        payload = {"sd_model_checkpoint": model_name}
        res = requests.post(OPTIONS_URL, json=payload)
        res.raise_for_status()
        print(f"âœ… Model switched to: {model_name}")
    except Exception as e:
        print(f"âŒ Failed to switch model: {e}")

# === âœ… ç”¢åœ– ===
def generate_image_from_prompt(prompt: str, width=640, height=832, steps=28, cfg_scale=8.5):
    payload = {
        "prompt": prompt,
        "negative_prompt": "low quality, worst quality, blurry, bad anatomy, watermark, extra limbs, text",
        "width": width,
        "height": height,
        "steps": steps,
        "cfg_scale": cfg_scale,
        "sampler_index": "Euler a"
    }

    try:
        print(f"ğŸ¨ Generating image for prompt: {prompt}")
        res = requests.post(TXT2IMG_URL, json=payload)
        res.raise_for_status()
        image_data = res.json()["images"][0]
        img = base64.b64decode(image_data)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{OUTPUT_DIR}/txt2img_{timestamp}.png"
        with open(filename, "wb") as f:
            f.write(img)

        print(f"âœ… Image saved: {filename}")
        return filename
    except Exception as e:
        print(f"âŒ Error generating image: {e}")
        return None

# === âœ… ä¸»ç¨‹å¼ ===
if __name__ == "__main__":
    if not is_webui_running():
        if not launch_webui():
            exit("âŒ Failed to launch WebUI.")

    models = list_available_models()
    # ğŸ‘‰ è«‹æ›¿æ›ä¸‹æ–¹ç‚ºä½ å¯¦éš›çœ‹åˆ°çš„æ¨¡å‹åç¨±ï¼ˆå« hashï¼‰
    model_to_use = "v1-5-pruned-emaonly.safetensors [6ce0161689]"
    if model_to_use in models:
        switch_model(model_to_use)
    else:
        print(f"âš ï¸ æ¨¡å‹ {model_to_use} ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­ï¼Œè«‹ç¢ºèªåç¨±æ˜¯å¦æ­£ç¢ºã€‚")

    # âœ… å¯¦éš›ç”¢åœ–
    prompt = "masterpiece, best quality, 1girl, white dress, floating, sunlight, backlight, cinematic"
    generate_image_from_prompt(prompt)
